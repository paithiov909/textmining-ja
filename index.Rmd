--- 
title: "RとMeCabによる日本語テキストマイニングの前処理"
author: "Akiru Kato"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: ["book.bib", "packages.bib"]
url: "https://paithiov909.github.io/textmining-ja/"
# cover-image: path to the social sharing image like images/cover.jpg
description: |
  Rによる自然言語処理・テキスト分析の練習
link-citations: yes
github-repo: paithiov909/textmining-ja
---

# はじめに {-#about}

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

## この資料について

### この資料でやりたいこと

[gibasa](https://github.com/paithiov909/gibasa)やその他のRパッケージを使って、RMeCabでできるようなテキストマイニングの前処理をより見通しよくおこなうやり方を紹介します。

### 想定する知識など

R言語の基本的な使い方の説明はしません。tidyverseなどの使い方については、他の資料を参照してください。

## Rでテキストマイニングするということ

### テキストを分析して何がしたいのか

テキストマイニングに関する入門的な本だと、「テキストマイニングとは何か」みたいな話から入るような気がします。ここでは必ずしも入門的な内容をめざしてはいませんが、しかし、すこし考えてみましょう。テキストマイニングとはなんでしょうか。

自然言語処理というのは、まあいろいろと思想はあるでしょうが、総じて「テキストを機械的に処理してごにょごにょする」技術のことだと思います。自然言語処理界隈の論文などを眺めていると、その範囲はかなり広くて、文書要約から文書生成といったタスクまで含まれるようです。

そのなかでもテキストマイニングというと、「テキストから特徴量をつくって何かを分析する」みたいな部分にフォーカスしてくるのではないでしょうか。

素人考えですが、テキストマイニングとはしたがってデータ分析のことです。そのため、前提としてテキストを分析して何がしたいのか（＝何ができるのか）を見通しよくしておくと、嬉しいことが多い気がします。

### テキストマイニングでめざすこと・できること

CRISP-DM ([Cross-Industry Standard Process for Data Mining](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining)) は、IBMを中心としたコンソーシアムが提案したデータマイニングのための標準プロセスです。

これはデータ分析をビジネスに活かすことを念頭においてつくられた「課題ドリブン」なプロセスであるため、場合によってはそのまま採用できないかもしれませんが、こうした標準プロセスを押さえておくことは、分析プロセスを設計するうえで有用だと思います。

CRISP-DMは以下の6つの段階（phases）を行ったり来たりすることで進められていきます。

- Business Understanding
- Data Understanding
- Data Preparation
- Modeling
- Evaluation
- Deployment

CRISP-DMはデータ分析を通じて達成したいことから分析をスタートしていく、ある意味でトップダウン的なプロセスです。しかし、データからの知見の発掘はそんなにトップダウン一直線にはうまくいかないものです。いわばボトムアップ的にも、段階を「行ったり来たり」しながら分析を進めるためには、データ分析でとれるカードをなんとなく把握しておく必要があります。

これも素人考えですが、私たちがデータ分析でとれるカードというのは、だいたい次の３つくらいのものです。

- モデルをつくって何かの回帰をする
- モデルをつくって何かの分類をする
- グループに分けて違いを評価する

そのために、これらの落としどころに持ち込むためのテキストの特徴量をどうにかしてつくること（前処理）が、私たちが実際におこなうテキストマイニングの大きな部分を占めるように思います。

そして、それらの特徴量は、テキストについて何かを数えた頻度または比率とそれらを変換したものだと思っておくとすっきりします。数を数える「何か」というのは、たとえば語だったり品詞だったり、それらのNgramだったり、その他のタグ付けされた情報だったりします。

### テキストマイニングの流れ

テキストマイニングの大まかな流れは、イメージ的には、次のような感じになります。

1. 分析したいテキストをいっぱい集める

- 分析して何がしたいか考える
- そのためにつくるべき特徴量を考える

2. 特徴量をつくる

- 正規化などの文字列処理
- トークナイズ・ステミング・レメタイズ
- 集計
- 特徴量の変換や補完

3. 分析する

- 特徴量をつかってデータ分析する
- 得られた結果を評価する

4. （必要に応じて）得られた知見を活かす

この資料では、この流れのなかでも、2にとくにフォーカスして、テキストの前処理のやり方を説明します。
